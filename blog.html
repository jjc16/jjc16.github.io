<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Blog</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link type="application/atom+xml" rel="alternate" href="/feed.xml" />
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Blog</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Blog" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Blog" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Blog","url":"/blog.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <nav>
  
    <a href="/" >Home</a>
  
    <a href="/about.html" >About</a>
  
    <a href="/blog.html" class="current">Blog</a>
  
    <a href="/authors.html" >Author(s)</a>
  
    <a href="/disclaimer.html" >Disclaimer</a>
  
</nav>
  
    <ul>
  
    <li>
	    <h2><a href="/jjc16.github.io/2023/04/15/News_On_ChatGPT-5_Training.html">News_on_chatgpt 5_training</a></h2> 
     <p>According to the latest publicly available information, OpenAI is not currently training GPT-5 and “won’t for some time”. In public news releases, OpenAI seems to hint at an operational pause to implement greater AI safety and model transparency. An example article to read about this can be found <a href="https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman">here</a>.While it’s likely that greater safety has <em>something</em> to do with the pause, I’m not convinced that this is the full story. I believe it’s likely that OpenAI ran into difficulties with training GPT-5 (rumored to contain 10 trillion parameters) and decided to put their money towards trying to make GPT-4 better instead.</p>

    </li>
  
    <li>
	    <h2><a href="/2023/04/15/News_On_ChatGPT-5_Training.html">News_on_chatgpt 5_training</a></h2> 
     <p>According to the latest publicly available information, OpenAI is not currently training GPT-5 and “won’t for some time”. In public news releases, OpenAI seems to hint at an operational pause to implement greater AI safety and model transparency. An example article to read about this can be found <a href="https://www.theverge.com/2023/4/14/23683084/openai-gpt-5-rumors-training-sam-altman">here</a>.While it’s likely that greater safety has <em>something</em> to do with the pause, I’m not convinced that this is the full story. I believe it’s likely that OpenAI ran into difficulties with training GPT-5 (rumored to contain 10 trillion parameters) and decided to put their money towards trying to make GPT-4 better instead.</p>

    </li>
  
    <li>
	    <h2><a href="/jjc16.github.io/2023/04/14/Initial_Post.html">Initial_post</a></h2> 
     <p>This is the first post of my new blog.</p>

    </li>
  
    <li>
	    <h2><a href="/2023/04/14/Initial_Post.html">Initial_post</a></h2> 
     <p>This is the first post of my new blog.</p>

    </li>
  
</ul>


  </body>
</html>
